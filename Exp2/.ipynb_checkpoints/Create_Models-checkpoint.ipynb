{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1a6aa6",
   "metadata": {},
   "source": [
    "# Create all models (S, D, P, C) from Null Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f472d",
   "metadata": {},
   "source": [
    "Starting from our previous null model (connectome-derived ESN), we will **subtract** topological features to determine their impact on performance and variance. Specifically, we will create models corresponding to each subtracted feature: models S, D, P, and C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fecef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load null reservoir\n",
    "with open('Model_Files/null.npy', 'rb') as f:\n",
    "    model_null = np.load(f)\n",
    "\n",
    "display(model_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec16eeb",
   "metadata": {},
   "source": [
    "### Create model S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c3f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get array sparsity\n",
    "def get_sparsity(array):\n",
    "    #display(array.size)\n",
    "    return np.count_nonzero(array)/array.size\n",
    "\n",
    "# function to decrease null sparsity to 20%\n",
    "def decrease_sparsity(dataframe):\n",
    "    values_to_add = np.zeros(1) \n",
    "    \n",
    "    #bootstrap to get population array values\n",
    "    num_boot = 50\n",
    "    for i in range(num_boot):\n",
    "        df_star = dataframe.sample(len(dataframe),replace=True)\n",
    "        df_star_arr = df_star.values\n",
    "        nonzero_vals = df_star_arr[df_star_arr!=0]\n",
    "        \n",
    "        # add 2000 values to values_to_add array\n",
    "        values_to_add = np.concatenate((values_to_add,pd.DataFrame(nonzero_vals).sample(2000,replace=False).values),axis=None)\n",
    "        \n",
    "    # replace random zero values with values from population (bootstrapped)\n",
    "    df_arr = dataframe.values\n",
    "    for i in range(len(df_arr)):\n",
    "        for j in range(len(df_arr)):\n",
    "            if(np.random.rand() > 0.81 and df_arr[i,j]==0): #with % chance, if zero value then replace\n",
    "                df_arr[i,j] = np.random.choice(values_to_add)\n",
    "        #if(i%100==0):\n",
    "            #print(i)\n",
    "    return df_arr, values_to_add\n",
    "\n",
    "\n",
    "display(get_sparsity(model_null))\n",
    "new_arr,vals_connectome_bootstrapped = decrease_sparsity(pd.DataFrame(model_null)) #decrease sparsity, starting from the null model\n",
    "display(get_sparsity(new_arr))\n",
    "\n",
    "# save the new reservoir as Model S\n",
    "with open('S_null_sparse.npy', 'wb') as f:\n",
    "    np.save(f, new_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7194202",
   "metadata": {},
   "source": [
    "### Create model D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-sample all values from uniform distribution\n",
    "\n",
    "# start from the null model\n",
    "with open('Model_Files/null.npy', 'rb') as f:\n",
    "    modelb = np.load(f)\n",
    "\n",
    "b_mask = modelb != 0 #create mask to find nonzero locations\n",
    "display(b_mask)\n",
    "\n",
    "c = np.count_nonzero(b_mask) # count nonzero values\n",
    "display(c)\n",
    "\n",
    "# # create model b by sampling from uniform distr.\n",
    "vals = np.where(True, np.random.randint(0,10000, c) , 0)\n",
    "display(vals.size)\n",
    "\n",
    "# # Assign the sampled values into the b reservoir\n",
    "modelb[b_mask] = vals\n",
    "display(modelb)\n",
    "\n",
    "# # for uniform distribution on [0,1)\n",
    "result = np.linalg.norm(modelb)\n",
    "display(result)\n",
    "new_b=modelb/result\n",
    "\n",
    "display(new_b)\n",
    "# # save model B\n",
    "with open('D_null_uniform.npy', 'wb') as f:\n",
    "    np.save(f, new_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf0e35",
   "metadata": {},
   "source": [
    "### Create model P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permute row-wise and col-wise while retaining zero positions\n",
    "with open('Model_Files/null.npy', 'rb') as f:\n",
    "    modelb2 = np.load(f)\n",
    "\n",
    "print(\"permute across row...\")\n",
    "\n",
    "#permute across row\n",
    "for i in range(len(modelb2)):\n",
    "    idx = np.nonzero(modelb2[i])\n",
    "    modelb2[i][idx] = np.random.permutation(modelb2[i][idx])\n",
    "\n",
    "#display(modelb2)\n",
    "print(\"then across column...\")\n",
    "\n",
    "#then permute across col\n",
    "for j in range(modelb2.shape[1]):\n",
    "    idy = np.nonzero(modelb2[:,j])\n",
    "    modelb2[idy,j] = np.random.permutation(modelb2[idy][:,j])\n",
    "\n",
    "print(\"permute across row...\")\n",
    "\n",
    "#permute across row\n",
    "for i in range(len(modelb2)):\n",
    "    idx = np.nonzero(modelb2[i])\n",
    "    modelb2[i][idx] = np.random.permutation(modelb2[i][idx])\n",
    "\n",
    "#display(modelb2)\n",
    "print(\"then across column...\")\n",
    "\n",
    "#then permute across col\n",
    "for j in range(modelb2.shape[1]):\n",
    "    idy = np.nonzero(modelb2[:,j])\n",
    "    modelb2[idy,j] = np.random.permutation(modelb2[idy][:,j])\n",
    "    \n",
    "print(\"permute across row...\")\n",
    "\n",
    "#permute across row\n",
    "for i in range(len(modelb2)):\n",
    "    idx = np.nonzero(modelb2[i])\n",
    "    modelb2[i][idx] = np.random.permutation(modelb2[i][idx])\n",
    "\n",
    "#display(modelb2)\n",
    "print(\"then across column...\")\n",
    "\n",
    "#then permute across col\n",
    "for j in range(modelb2.shape[1]):\n",
    "    idy = np.nonzero(modelb2[:,j])\n",
    "    modelb2[idy,j] = np.random.permutation(modelb2[idy][:,j])\n",
    "    \n",
    "display(modelb2)\n",
    "\n",
    "# save model B2\n",
    "with open('P_null_permute.npy', 'wb') as f:\n",
    "    np.save(f, modelb2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd00de",
   "metadata": {},
   "source": [
    "### Create model C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b903f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null C = 0.43; Wish to increase C to 0.5 (Erdos-Renyi)\n",
    "with open('Model_Files/null.npy', 'rb') as f:\n",
    "    null = np.load(f)\n",
    "\n",
    "## Uncomment code below to check C for null reservoir\n",
    "#g_modelc = nx.from_numpy_array(null)\n",
    "#display(nx.average_clustering(g_modelc)) # ~0.27001990732141884\n",
    "\n",
    "# convert null reservoir to graph with networkx\n",
    "g_newc = nx.from_numpy_array(null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, order the clustering coefficients of all nodes in the reservoir (in reverse order)\n",
    "clustering_per_node = nx.clustering(g_newc)\n",
    "sorted_clustering = sorted(clustering_per_node.items(), key=lambda x: x[1], reverse=True)\n",
    "#display(sorted_clustering)\n",
    "\n",
    "# for only the mid-high clustering nodes add weights. First, try making list of intermediate-C nodes\n",
    "# Then, add weighted edges from bootstrap to these (i.e. from the bootstrap we did for model A)\n",
    "#display(sorted_clustering[500:700])\n",
    "\n",
    "#display(len(sorted_clustering))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eff8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sorted_clustering[3993])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6416005",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_highcc = []\n",
    "#2000 to 2600 was good\n",
    "for i in range(2800,3300): \n",
    "    list_highcc.append(sorted_clustering[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50000):\n",
    "    # here we add new edges to intermediate nodes (randomly chosen). Which weights? Those from bootstrap (recall \"vals\").\n",
    "    g_newc.add_weighted_edges_from([(np.random.choice(list_highcc),np.random.choice(list_highcc),np.random.choice(vals_connectome_bootstrapped))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is our C now ~0.5? If not, re-run this cell. If so, done.\n",
    "display(nx.average_clustering(g_newc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851467ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model C once clustering coefficient matches random graph (0.5)\n",
    "modelc = nx.to_numpy_array(g_newc)\n",
    "with open('C_null_clustering.npy', 'wb') as f:\n",
    "    np.save(f, modelc)\n",
    "# final number is 0.5044721209428997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ee5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as another idea, use the random graph we made to find the clustering coef.. then match that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
